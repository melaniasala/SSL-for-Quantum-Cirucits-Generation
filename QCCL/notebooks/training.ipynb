{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\melan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\melan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\melan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\melan\\AppData\\Local\\Temp\\ipykernel_13192\\782632694.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "c:\\Users\\melan\\shared-folder\\Thesis\\SSL-for-Quantum-Cirucits-Generation\\qiskit_env\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Data import GraphDataset\n",
    "from Models import GCNFeatureExtractor\n",
    "from utils.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pre_paired = True\n",
    "batch_size = 4\n",
    "lr = 1e-3\n",
    "epochs = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "embedding_size = 50\n",
    "pooling = 'last_avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCollected 1 sample from null_ops.\n",
      "\tCollected 4 samples from commutations.\n",
      "\tCollected 7 samples from equivalences.\n",
      "\tCollected 7 samples from combined.\n",
      "Loaded 19 samples and 19 quantum circuits from subset.\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "from Data import load_graphs\n",
    "\n",
    "basic_data, _ = load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# def load_graphs(data_dir='../Data/raw/', file_name='handcrafted_dataset.pkl', subset=None):\n",
    "#     file_path = os.path.join(data_dir, file_name)\n",
    "#     graphs, qcs = [], []\n",
    "    \n",
    "#     with open(file_path, 'rb') as f:\n",
    "#         dataset = pickle.load(f)\n",
    "\n",
    "#     if file_name == 'handcrafted_dataset.pkl':\n",
    "#         if subset is not None:\n",
    "#             dataset = dataset[subset]\n",
    "#             print(f\"Loaded {len(dataset)} elements from subset {subset}:\")\n",
    "#         # collect all graphs in dataset, which are stored in a nested dictionary\n",
    "#         dataset = collect_from_dict(dataset) \n",
    "\n",
    "#     # extract graphs and qcs separately, if needed\n",
    "#     for sample in dataset:\n",
    "#         if isinstance(sample, tuple): # if a tuple (qc, graph)\n",
    "#             g, qc = sample\n",
    "#             graphs.append(g)\n",
    "#             qcs.append(qc)\n",
    "#         elif all(isinstance(graph, tuple) for graph in sample):# if a list of tuples (qc, graph) \n",
    "#             g, qc = zip(*sample)\n",
    "#             qcs.append(list(qc))\n",
    "#             graphs.append(list(g))\n",
    "\n",
    "#     print(f\"Loaded {len(graphs)} samples and {len(qcs)} quantum circuits from subset.\")\n",
    "    \n",
    "#     return graphs, qcs\n",
    "\n",
    "# def collect_from_dict(dictionary):\n",
    "#     graphs = []\n",
    "#     for k, v in dictionary.items():\n",
    "#         if isinstance(v, dict):\n",
    "#             graphs.extend(collect_from_dict(v))\n",
    "#         elif isinstance(v, list):\n",
    "#             if all(isinstance(item, list) for item in v):  # if list of lists\n",
    "#                 graphs.extend(v)\n",
    "#                 print(f\"\\tCollected {len(v)} items from {k}.\")\n",
    "#             elif all(isinstance(item, tuple) for item in v):  # if list of tuples\n",
    "#                 graphs.append(v)\n",
    "#                 print(f\"\\tCollected 1 sample from {k}.\")\n",
    "                \n",
    "#     return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic transforms training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphDataset(basic_data, pre_paired=use_pre_paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "graphs = basic_data[0]\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "def get_attr_matrix(graph):\n",
    "    nodes_list = list(graph.nodes)\n",
    "    nodes_view = graph.nodes(data=True)\n",
    "    return np.array([nodes_view[node]['feature_vector'] for node in nodes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODE FEATURES:\n",
      "[[0 1 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [1 0 0 0 0 1]]\n",
      "[[0 1 0 0 0 0]\n",
      " [1 0 0 0 1 0]\n",
      " [1 0 0 0 0 1]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "---\n",
      "tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.]])\n",
      "ADJACENCY:\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "[[0 1 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]]\n",
      "---\n",
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 1]])\n",
      "tensor([[0, 1, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Check if graphs in the dataset are correctly converted to PyTorch Geometric Data objects\n",
    "graphs = [basic_data[0][0:2]]\n",
    "dataset_1 = GraphDataset(graphs, pre_paired=use_pre_paired)\n",
    "\n",
    "data_1, data_2 = dataset_1[0]\n",
    "\n",
    "print(\"NODE FEATURES:\")\n",
    "\n",
    "print(get_attr_matrix(graphs[0][0]))\n",
    "print(get_attr_matrix(graphs[0][1]))\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(data_1.x)\n",
    "print(data_2.x)\n",
    "\n",
    "print(\"ADJACENCY:\")\n",
    "\n",
    "print(nx.adjacency_matrix(graphs[0][0]).todense())\n",
    "print(nx.adjacency_matrix(graphs[0][1]).todense())\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(data_1.edge_index)\n",
    "print(data_2.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Data.Dataset.GraphDataset at 0x1882b844650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the dataset: 6\n"
     ]
    }
   ],
   "source": [
    "n_features = dataset[0][0].x.shape[1] if use_pre_paired else dataset[0].x.shape[1]\n",
    "print(f'Number of features in the dataset: {n_features}')\n",
    "gnn = GCNFeatureExtractor(in_channels=n_features, out_channels=embedding_size, pooling_strategy=pooling)\n",
    "\n",
    "# model = torch.nn.Sequential(gnn).to(device) # TODO: see todo in next cell\n",
    "model = gnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(model, dataset, epochs, batch_size, device=device)\n",
    "\n",
    "\n",
    "# TODO: nn.Sequential expexts a single input, not multiple ones as happens for GNNs (x, edge_index, batch)\n",
    "# You have to find a way to stack several models, without using nn.Sequential, or to wrap the GNN in a class \n",
    "# that handles a single input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
